{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "test\n",
      "SS\n",
      "PCA\n",
      "Birch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd                                             # importing pandas\n",
    "import numpy as np                                              # importing numpy\n",
    " \n",
    "\n",
    "training_data = pd.read_csv(\"data_tr.txt\",sep='\\t',header=None) # loading training dataset file\n",
    "labels=pd.read_csv(\"gene_names.txt\",header=None)                # loading gene names file\n",
    "col=labels[0].tolist()\n",
    "training_data.columns=col                               # setting gene names as column names of gene dataset for training data\n",
    "\n",
    "test = pd.read_csv(\"data_ts.txt\",sep='\\t',header=None)  # loading testing dataset file\n",
    "test.columns=col                                        # setting gene names as column names of gene dataset for testing data\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  # importing Standard Scaler from sklearn.preprocessing  \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(training_data)                         # training Standard Scaler with the help of fit() function\n",
    "trainingdata=scaler.transform(training_data)      # Standardizing training dataset with the help of transform() function\n",
    "\n",
    "testdata=scaler.transform(test)                   # Standardizing testing dataset with the help of transform() function\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA            # importing PCA from sklearn.decomposition\n",
    "pca = PCA(n_components=47, random_state=5)       \n",
    "pca.fit(trainingdata)                            # training PCA on training dataset\n",
    "pc = pca.transform(trainingdata)                 # reducing dimentions of training dataset to 47 using PCA\n",
    "\n",
    "pct = pca.transform(testdata)                    # reducing dimentions of testing dataset to 47 using PCA\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.cluster import Birch               # importing Birch from sklearn.cluster\n",
    "model2= Birch(n_clusters=16, threshold=2)       # setting parameters of Birch\n",
    "model2.fit(pc)                                  # training Birch model on training data\n",
    "predictions2= model2.predict(pc)            # predicting clusters of training data and storing them into predictions2 variable\n",
    "\n",
    "predictions= model2.predict(pct)   # predicting clusters of testing data and storing them into predictions variable\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Score : \n",
      "0.8471130951585165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"API Score : \")\n",
    "import json\n",
    "import requests\n",
    "url = \"https://www.csci555competition.online/scoretest\"\n",
    "\n",
    "payload = json.dumps(predictions.tolist())\n",
    "headers = {\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
